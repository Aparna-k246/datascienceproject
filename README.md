# ğŸ§  End-to-End Data Science Project

A complete production-grade ML pipeline built using modular architecture: from data ingestion to model evaluation, with YAML config-driven design, component-based codebase, and frontend API endpoints. Ideal for real-world deployment & recruiter showcase.

---

## âš™ï¸ Workflows â€“ ML Pipeline

1. ğŸ”½ **Data Ingestion**
2. âœ… **Data Validation**
3. ğŸ” **Data Transformation** â€“ Feature Engineering, Data Preprocessing
4. ğŸ¤– **Model Trainer**
5. ğŸ“Š **Model Evaluation** â€“ using **MLflow** & **DagsHub**

---

## ğŸ§  Full Project Workflow

1. ğŸ› ï¸ Update `config.yaml`
2. ğŸ§¬ Update `schema.yaml`
3. ğŸ“Š Update `params.yaml`
4. ğŸ§± Update the `config_entity.py` under `entity`
5. âš™ï¸ Update the `Configuration Manager` under `src/config/`
6. ğŸ§© Update the `components`:  
   - `data_ingestion.py`  
   - `data_validation.py`  
   - `data_transformation.py`  
   - `model_trainer.py`  
   - `model_evaluation.py`  
7. ğŸ§ƒ Create Pipelines:  
   - `data_ingestion_pipeline.py`  
   - `data_validation_pipeline.py`  
   - `data_transformation_pipeline.py`  
   - `model_trainer_pipeline.py`  
   - `model_evaluation_pipeline.py`  
   - `prediction_pipeline.py`  
8. ğŸš€ Run with `main.py`

---

## ğŸŒ Frontend

- `app.py`: Flask App
- `templates/`: `index.html`, `results.html`
- API Endpoints:
  - `/predict`
  - `/train`
  - `/batch-predict`

---

## ğŸ§° Tech Stack

- Python ğŸ
- Scikit-learn ğŸ”
- Pandas & NumPy ğŸ“Š
- MLFlow ğŸ”„
- Flask ğŸŒ
- YAML-based Configuration ğŸ“„
- Docker ğŸ³ (optional)
- GitHub Actions CI/CD âš™ï¸

---

## ğŸ§¾ Folder Structure

```
.gthub/
    â””â”€â”€ workflows/
config/
    â””â”€â”€ config.yaml
research/
    â”œâ”€â”€ 1_data_ingestion.ipynb
    â”œâ”€â”€ 2_data_validation.ipynb
    â”œâ”€â”€ 3_data_transformation.ipynb
    â”œâ”€â”€ 4_model_trainer.ipynb
    â”œâ”€â”€ 5_model_evaluation.ipynb
src/
 â””â”€â”€ datascience/
     â”œâ”€â”€ components/
     â”‚   â”œâ”€â”€ data_ingestion.py
     â”‚   â”œâ”€â”€ data_validation.py
     â”‚   â”œâ”€â”€ data_transformation.py
     â”‚   â”œâ”€â”€ model_trainer.py
     â”‚   â””â”€â”€ model_evaluation.py
     â”œâ”€â”€ config/
     â”‚   â””â”€â”€ configuration.py
     â”œâ”€â”€ entity/
     â”‚   â””â”€â”€ config_entity.py
     â”œâ”€â”€ pipeline/
     â”‚   â”œâ”€â”€ data_ingestion_pipeline.py
     â”‚   â”œâ”€â”€ data_validation_pipeline.py
     â”‚   â”œâ”€â”€ data_transformation_pipeline.py
     â”‚   â”œâ”€â”€ model_trainer_pipeline.py
     â”‚   â”œâ”€â”€ model_evaluation_pipeline.py
     â”‚   â””â”€â”€ prediction_pipeline.py
     â”œâ”€â”€ utils/
     â”‚   â””â”€â”€ common.py
templates/
    â”œâ”€â”€ index.html
    â””â”€â”€ results.html
params.yaml
schema.yaml
requirements.txt
main.py
app.py
README.md
```

---

## ğŸ‘©â€ğŸ’¼ For Recruiters

âœ… **Real-World Ready**: Modular, YAML-configured, CI/CD-ready  
âœ… **Explainable**: Every step has `research.ipynb` for experiments  
âœ… **Extensible**: Easily plug and play with other models or APIs  
âœ… **Frontend + Backend**: Comes with Flask + HTML templates  
âœ… **Proven Stack**: Uses MLFlow, DagsHub, YAML, and component abstraction

---

## ğŸš€ How to Run

```bash
# 1. Clone the repo
git clone https://github.com/Aparna-k246/datascienceproject.git

# 2. Create virtual environment
python -m venv venv
source venv/bin/activate  # or venv\Scripts\activate on Windows

# 3. Install requirements
pip install -r requirements.txt

# 4. Run the main pipeline
python main.py

# 5. Launch the app
python app.py
```


## ğŸ“ License

This project is open-source and available under the [MIT License](LICENSE).

---

ğŸŒŸ **Give this repo a star if you found it helpful!**  
